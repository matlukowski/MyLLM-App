import express, { Express, Request, Response } from "express";
import cors from "cors";
import { PrismaClient } from "@prisma/client";
import bcrypt from "bcrypt";
import path from "path";
import {
  upload,
  convertFileToText,
  formatFileSize,
  validateFile,
  deleteFile,
  fileExists,
} from "./utils/fileUtils";
import VectorMemoryService from "./services/VectorMemoryService";
import IntentAnalyzer, { type MemoryAggressiveness } from "./services/IntentAnalyzer";

// Inicjalizacje
const prisma = new PrismaClient();
const app: Express = express();
const vectorMemoryService = new VectorMemoryService(prisma);

// Initialize VectorMemoryService (fixed for single user mode)
async function initializeVectorMemory() {
  try {
    await vectorMemoryService.initialize();
    console.log('ğŸ§  VectorMemoryService initialized for single user mode');
  } catch (error) {
    console.error('âŒ Failed to initialize VectorMemoryService:', error);
    console.log('ğŸ“± Desktop app will work without vector memory - basic chat functionality available');
  }
}

// Middlewares
app.use(
  cors({
    origin: ["http://localhost:3000", "http://localhost:5173"],
  })
);
app.use(express.json());

// Serwowanie statycznych plikÃ³w z katalogu uploads
app.use("/uploads", express.static(path.join(__dirname, "../uploads")));

// --- API Endpoints ---

// AUTH ENDPOINTS REMOVED FOR SINGLE USER MODE
// No login/register needed - app works with single local user

// Single User Mode - hardcoded user ID
const SINGLE_USER_ID = "single-user";

// Pobierz listÄ™ czatÃ³w dla uÅ¼ytkownika (single user mode)
app.get("/api/chats", async (req: Request, res: Response) => {
  // Use hardcoded single user ID
  const loggedInUserId = SINGLE_USER_ID;

  try {
    const chats = await prisma.chat.findMany({
      orderBy: { updatedAt: "desc" },
      include: {
        messages: {
          orderBy: { createdAt: "desc" },
          take: 1,
        },
      },
    });

    const chatList = chats.map((chat) => {
      const lastMessage = chat.messages[0];
      const metadata = chat.metadata as any;

      return {
        id: chat.id,
        title: chat.title || "Nowa rozmowa",
        lastMessage: lastMessage?.content || "",
        lastMessageTime: lastMessage?.createdAt || chat.createdAt,
        messageCount: chat.messages.length,
        modelId: metadata?.modelId || "unknown",
        userId: loggedInUserId, // Keep for frontend compatibility
        isAIChat: metadata?.isAIChat || false,
        createdAt: chat.createdAt,
        updatedAt: chat.updatedAt,
      };
    });

    res.json(chatList);
  } catch (error) {
    console.error("Error fetching chats:", error);
    res.status(500).json({ error: "Could not fetch chats" });
  }
});

// Pobierz wiadomoÅ›ci dla konkretnego czatu (z paginacjÄ…)
app.get("/api/chats/:chatId/messages", async (req: Request, res: Response) => {
  const { chatId } = req.params;
  const { cursor } = req.query; // Dla paginacji (ID ostatniej wiadomoÅ›ci)

  try {
    const messages = await prisma.message.findMany({
      where: { chatId },
      take: 30,
      ...(cursor && { skip: 1, cursor: { id: String(cursor) } }),
      orderBy: { createdAt: "desc" },
    });
    
    // Transform messages to include sender info for frontend compatibility
    const transformedMessages = messages.map(message => ({
      ...message,
      sender: {
        id: message.senderType === "user" ? SINGLE_USER_ID : "ai-assistant",
        username: message.senderType === "user" ? "User" : "AI"
      }
    }));
    
    res.json(transformedMessages.reverse());
  } catch (error) {
    console.error("Error fetching messages:", error);
    res.status(500).json({ error: "Could not fetch messages" });
  }
});

// Endpoint do tworzenia nowego czatu AI
app.post("/api/ai/chats", async (req: Request, res: Response) => {
  const { title, modelId } = req.body; // userId no longer needed

  if (!title || !modelId) {
    return res.status(400).json({
      error: "title i modelId sÄ… wymagane",
    });
  }

  try {
    // UtwÃ³rz nowy czat AI
    const newChat = await prisma.chat.create({
      data: {
        title,
        // Dodaj metadane czatu AI
        metadata: {
          modelId,
          isAIChat: true,
        },
      } as any, // Rzutowanie typu dla pÃ³l title i metadata
      include: {
        messages: {
          orderBy: { createdAt: "desc" },
          take: 1,
        },
      },
    });

    console.log("âœ… Utworzono nowy czat AI:", newChat.id);
    res.status(201).json(newChat);
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d tworzenia czatu AI:", error);
    res.status(500).json({ error: "Nie udaÅ‚o siÄ™ utworzyÄ‡ czatu AI" });
  }
});

// Endpoint do usuwania czatu
app.delete("/api/chats/:chatId", async (req: Request, res: Response) => {
  const { chatId } = req.params;

  try {
    // SprawdÅº czy czat istnieje
    const chat = await prisma.chat.findFirst({
      where: { id: chatId },
    });

    if (!chat) {
      return res
        .status(404)
        .json({ error: "Czat nie zostaÅ‚ znaleziony" });
    }

    // SprawdÅº czy uÅ¼ytkownik chce automatycznie usuwaÄ‡ pamiÄ™Ä‡
    let memoryDeletedCount = 0;
    if (vectorMemoryService.isReady()) {
      try {
        const userSettings = await prisma.memorySettings.findFirst();
        
        if (userSettings?.autoDeleteOnChatRemoval !== false) {
          // DomyÅ›lnie usuÅ„ pamiÄ™Ä‡ (chyba Å¼e uÅ¼ytkownik wyÅ‚Ä…czyÅ‚)
          memoryDeletedCount = await vectorMemoryService.deleteMemoryByChat(chatId);
          console.log(`ğŸ—‘ï¸ Automatycznie usuniÄ™to pamiÄ™Ä‡ czatu (ustawienie: ${userSettings?.autoDeleteOnChatRemoval})`);
        } else {
          console.log(`ğŸ”’ Zachowano pamiÄ™Ä‡ czatu (ustawienie uÅ¼ytkownika)`);
        }
      } catch (error) {
        console.error("âŒ BÅ‚Ä…d usuwania pamiÄ™ci wektorowej:", error);
        // Nie przerywamy procesu - pamiÄ™Ä‡ moÅ¼na wyczyÅ›ciÄ‡ pÃ³Åºniej
      }
    }

    // UsuÅ„ wszystkie wiadomoÅ›ci z czatu
    await prisma.message.deleteMany({
      where: { chatId },
    });

    // UsuÅ„ czat
    await prisma.chat.delete({
      where: { id: chatId },
    });

    console.log("âœ… UsuniÄ™to czat:", chatId, `(${memoryDeletedCount} wpisÃ³w pamiÄ™ci)`);
    res.json({ 
      message: "Czat zostaÅ‚ usuniÄ™ty",
      memoryEntriesDeleted: memoryDeletedCount
    });
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d podczas usuwania czatu:", error);
    res.status(500).json({ error: "Nie udaÅ‚o siÄ™ usunÄ…Ä‡ czatu" });
  }
});

// Funkcja do generowania odpowiedzi AI z pamiÄ™ciÄ… wektorowÄ…
async function generateAIResponseWithMemory(
  userMessage: string,
  provider: string,
  apiKey: string,
  modelId: string,
  userId: string,
  chatId: string,
  attachments: any[] = []
): Promise<string> {
  const basicPrompt = `JesteÅ› inteligentnym asystentem AI. Odpowiadaj w sposÃ³b rzeczowy, pomocny i praktyczny.
JeÅ›li otrzymasz kontekst z poprzednich rozmÃ³w, wykorzystaj te informacje naturalnie.
Dostosowuj dÅ‚ugoÅ›Ä‡ odpowiedzi do zÅ‚oÅ¼onoÅ›ci pytania. BÄ…dÅº pozytywny i motywujÄ…cy, ale unikaj przesadnej empatii czy rozczulania siÄ™.
Skupiaj siÄ™ na rozwiÄ…zaniach i praktycznych poradach zamiast na wspÃ³Å‚czuciu.`;

  // PrzetwÃ³rz zaÅ‚Ä…czniki
  let attachmentContext = "";
  if (attachments && attachments.length > 0) {
    attachmentContext = "\n\nZaÅ‚Ä…czniki uÅ¼ytkownika:\n";

    for (const attachment of attachments) {
      try {
        const filePath = path.join(
          __dirname,
          "../uploads",
          path.basename(attachment.url)
        );
        if (fileExists(filePath)) {
          const fileContent = await convertFileToText(
            filePath,
            attachment.mimetype
          );
          attachmentContext += `\n${fileContent}\n`;
        } else {
          attachmentContext += `\n[BÅÄ„D: Plik ${attachment.filename} nie zostaÅ‚ znaleziony]\n`;
        }
      } catch (error) {
        console.error(
          `BÅ‚Ä…d przetwarzania zaÅ‚Ä…cznika ${attachment.filename}:`,
          error
        );
        attachmentContext += `\n[BÅÄ„D: Nie udaÅ‚o siÄ™ przetworzyÄ‡ pliku ${attachment.filename}]\n`;
      }
    }
  }

  // NOWA LOGIKA: Inteligentne wybieranie ÅºrÃ³dÅ‚a kontekstu
  let memoryContext = "";
  
  try {
    // 1. Pobierz dÅ‚ugoÅ›Ä‡ historii aktualnego czatu
    const chatHistoryCount = await prisma.message.count({
      where: { chatId }
    });

    // 2. Pobierz ustawienia pamiÄ™ci (single user mode)
    const userSettings = await prisma.memorySettings.findFirst();
    
    const aggressiveness = (userSettings?.memoryAggressiveness || 'conservative') as MemoryAggressiveness;

    // 3. Analizuj intencjÄ™ uÅ¼ytkownika
    const intentAnalysis = IntentAnalyzer.analyzeIntent(
      userMessage,
      chatHistoryCount,
      aggressiveness
    );

    console.log(`ğŸ§ Analiza intencji: ${intentAnalysis.detectedIntent} (ufnoÅ›Ä‡: ${intentAnalysis.confidence.toFixed(2)})`);
    console.log(`ğŸ’¡ Uzasadnienie: ${intentAnalysis.reasoning}`);

    // 4. Pobierz kontekst na podstawie analizy intencji
    if (intentAnalysis.useVectorMemory && vectorMemoryService.isReady()) {
      // UÅ¼yj pamiÄ™ci wektorowej
      memoryContext = await vectorMemoryService.getMemoryContext(
        userMessage,
        intentAnalysis.useChatHistory ? undefined : chatId, // Globalne vs lokalne
        1500
      );
      
      if (memoryContext) {
        console.log(`ğŸ§  UÅ¼ywam pamiÄ™ci wektorowej (${memoryContext.length} znakÃ³w)`);
      } else {
        console.log(`ğŸ¤· PamiÄ™Ä‡ wektorowa nie znalazÅ‚a relevant kontekstu`);
      }
    }
    
    // 5. Fallback do historii czatu jeÅ›li nie ma kontekstu z pamiÄ™ci wektorowej
    if (!memoryContext && intentAnalysis.useChatHistory && chatHistoryCount > 1) {
      const recentMessages = await prisma.message.findMany({
        where: { chatId },
        orderBy: { createdAt: 'desc' },
        take: 6
      });

      if (recentMessages.length > 1) {
        const chatHistory = recentMessages
          .reverse()
          .slice(0, -1) // UsuÅ„ aktualnÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika
          .map(msg => `${msg.senderType === 'user' ? 'User' : 'AI'}: ${msg.content}`)
          .join('\n');
        
        if (chatHistory) {
          memoryContext = `Historia z tego czatu:\n\n${chatHistory}`;
          console.log(`ğŸ“œ UÅ¼ywam historii czatu (${memoryContext.length} znakÃ³w)`);
        }
      }
    }

    // 6. Loguj koÅ„cowÄ… decyzjÄ™
    if (!memoryContext) {
      console.log(`ğŸ†• Brak dodatkowego kontekstu - traktuj jako nowe pytanie`);
    }

  } catch (error) {
    console.error('âŒ BÅ‚Ä…d analizy intencji lub pobierania kontekstu:', error);
    
    // Emergency fallback - historia czatu jeÅ›li wszystko inne zawiedzie
    try {
      const recentMessages = await prisma.message.findMany({
        where: { chatId },
        orderBy: { createdAt: 'desc' },
        take: 4
      });

      if (recentMessages.length > 1) {
        const chatHistory = recentMessages
          .reverse()
          .slice(0, -1)
          .map(msg => `${msg.senderType === 'user' ? 'User' : 'AI'}: ${msg.content}`)
          .join('\n');
        
        if (chatHistory) {
          memoryContext = `Historia z tego czatu:\n\n${chatHistory}`;
          console.log(`ğŸ†˜ Emergency fallback - historia czatu (${memoryContext.length} znakÃ³w)`);
        }
      }
    } catch (fallbackError) {
      console.error('âŒ Nawet fallback nie zadziaÅ‚aÅ‚:', fallbackError);
    }
  }

  // Buduj peÅ‚nÄ… wiadomoÅ›Ä‡ z kontekstem
  let fullMessage = userMessage;
  
  if (memoryContext) {
    fullMessage = `${memoryContext}\n\n---\n\nBieÅ¼Ä…ce pytanie uÅ¼ytkownika: ${userMessage}`;
  }
  
  fullMessage += attachmentContext;

  if (provider === "google") {
    try {
      const { GoogleGenerativeAI } = await import("@google/generative-ai");
      const genAI = new GoogleGenerativeAI(apiKey);

      // Mapowanie modeli Gemini
      const geminiModels = {
        "gemini-2.5-flash": "gemini-2.0-flash-exp",
        "gemini-2.5-pro": "gemini-2.0-flash-exp",
        "gemini-1.5-flash": "gemini-1.5-flash",
        "gemini-1.5-pro": "gemini-1.5-pro",
      };
      const modelName =
        geminiModels[modelId as keyof typeof geminiModels] ||
        "gemini-2.0-flash-exp";

      const model = genAI.getGenerativeModel({
        model: modelName,
        systemInstruction: basicPrompt,
        generationConfig: {
          maxOutputTokens: 4000,
          temperature: 0.7,
        },
      });

      const result = await model.generateContent(fullMessage);
      return (
        result.response.text() ||
        "Przepraszam, nie mogÄ™ wygenerowaÄ‡ odpowiedzi."
      );
    } catch (error) {
      throw new Error(`BÅ‚Ä…d Google Gemini: ${error}`);
    }
  } else if (provider === "openai") {
    try {
      const { OpenAI } = await import("openai");
      const openai = new OpenAI({ apiKey });

      const modelMapping = {
        "o3-2025-04-16": "o1-preview",
        "chatgpt-4o-latest-20250326": "gpt-4o",
        "gpt4-1": "gpt-4-turbo",
        "gpt4-1-mini": "gpt-4o-mini",
        "o4-mini-high": "o1-mini",
        "gpt-4o": "gpt-4o",
        "gpt-4": "gpt-4",
        "gpt-3.5-turbo": "gpt-3.5-turbo",
      };
      const openaiModel =
        modelMapping[modelId as keyof typeof modelMapping] || "gpt-4o";

      const response = await openai.chat.completions.create({
        model: openaiModel,
        messages: [
          { role: "system", content: basicPrompt },
          { role: "user", content: fullMessage },
        ],
        temperature: 0.7,
        max_tokens: 4000,
      });

      return (
        response.choices[0]?.message?.content ||
        "Przepraszam, nie mogÄ™ wygenerowaÄ‡ odpowiedzi."
      );
    } catch (error) {
      throw new Error(`BÅ‚Ä…d OpenAI: ${error}`);
    }
  } else if (provider === "anthropic") {
    try {
      const { Anthropic } = await import("@anthropic-ai/sdk");
      const anthropic = new Anthropic({ apiKey });

      const modelMapping = {
        "claude-opus-4-20250514-thinking-16k": "claude-3-5-sonnet-20241022",
        "claude-opus-4-20250514": "claude-3-opus-20240229", 
        "claude-sonnet-4-20250514": "claude-3-5-sonnet-20241022",
        "claude-3.5-sonnet": "claude-3-5-sonnet-20241022",
        "claude-3.5-haiku": "claude-3-5-haiku-20241022",
      };
      const claudeModel =
        modelMapping[modelId as keyof typeof modelMapping] ||
        "claude-3-5-sonnet-20241022";

      const response = await anthropic.messages.create({
        model: claudeModel,
        max_tokens: 4000,
        system: basicPrompt,
        messages: [{ role: "user", content: fullMessage }],
      });

      const content = response.content[0];
      if (content.type === "text") {
        return content.text;
      }
      return "Przepraszam, nie mogÄ™ wygenerowaÄ‡ odpowiedzi.";
    } catch (error) {
      throw new Error(`BÅ‚Ä…d Anthropic: ${error}`);
    }
  } else if (provider === "xai") {
    try {
      const { OpenAI } = await import("openai");
      const xai = new OpenAI({
        apiKey,
        baseURL: "https://api.x.ai/v1",
      });

      const modelMapping = {
        "grok-4-0709": "grok-beta",
      };
      const xaiModel =
        modelMapping[modelId as keyof typeof modelMapping] || "grok-beta";

      const response = await xai.chat.completions.create({
        model: xaiModel,
        messages: [
          { role: "system", content: basicPrompt },
          { role: "user", content: fullMessage },
        ],
        temperature: 0.7,
        max_tokens: 4000,
      });

      return (
        response.choices[0]?.message?.content ||
        "Przepraszam, nie mogÄ™ wygenerowaÄ‡ odpowiedzi."
      );
    } catch (error) {
      throw new Error(`BÅ‚Ä…d xAI: ${error}`);
    }
  } else if (provider === "deepseek") {
    try {
      const { OpenAI } = await import("openai");
      const deepseek = new OpenAI({
        apiKey,
        baseURL: "https://api.deepseek.com",
      });

      const modelMapping = {
        "deepseek-r1-0528": "deepseek-reasoner",
      };
      const deepseekModel =
        modelMapping[modelId as keyof typeof modelMapping] || "deepseek-reasoner";

      const response = await deepseek.chat.completions.create({
        model: deepseekModel,
        messages: [
          { role: "system", content: basicPrompt },
          { role: "user", content: fullMessage },
        ],
        temperature: 0.7,
        max_tokens: 4000,
      });

      return (
        response.choices[0]?.message?.content ||
        "Przepraszam, nie mogÄ™ wygenerowaÄ‡ odpowiedzi."
      );
    } catch (error) {
      throw new Error(`BÅ‚Ä…d DeepSeek: ${error}`);
    }
  } else {
    throw new Error(`NieobsÅ‚ugiwany dostawca: ${provider}`);
  }
}

// --- Endpointy do obsÅ‚ugi plikÃ³w ---

// Endpoint do przesyÅ‚ania plikÃ³w
app.post("/api/files/upload", (req: Request, res: Response) => {
  // @ts-ignore - Konflikt typÃ³w miÄ™dzy wersjami Express
  const uploadHandler = upload.single("file");

  // @ts-ignore - Konflikt typÃ³w miÄ™dzy wersjami Express
  uploadHandler(req, res, async (err: any) => {
    try {
      if (err) {
        console.error("âŒ BÅ‚Ä…d multer:", err);
        return res
          .status(400)
          .json({ error: err.message || "BÅ‚Ä…d przesyÅ‚ania pliku" });
      }

      const file = (req as any).file;
      if (!file) {
        return res.status(400).json({ error: "Nie przesÅ‚ano pliku" });
      }

      // Pobierz userId z body (bÄ™dzie wysÅ‚any przez frontend)
      const userId = (req as any).body?.userId;
      if (!userId) {
        return res.status(400).json({ error: "userId jest wymagany" });
      }

      // Walidacja pliku
      const validation = validateFile(file);
      if (!validation.isValid) {
        // UsuÅ„ plik jeÅ›li walidacja nie powiodÅ‚a siÄ™
        if (fileExists(file.path)) {
          await deleteFile(file.path);
        }
        return res.status(400).json({ error: validation.error });
      }

      // ZnajdÅº lub utwÃ³rz tymczasowy czat dla zaÅ‚Ä…cznikÃ³w
      let tempChat = await prisma.chat.findFirst({
        where: { title: "TEMP_ATTACHMENTS" },
      });

      if (!tempChat) {
        tempChat = await prisma.chat.create({
          data: {
            title: "TEMP_ATTACHMENTS",
            metadata: { isTemp: true },
          },
        });
      }

      // UtwÃ³rz tymczasowÄ… wiadomoÅ›Ä‡ dla zaÅ‚Ä…cznika
      const tempMessage = await prisma.message.create({
        data: {
          content: `[TEMP_ATTACHMENT_${Date.now()}]`,
          senderType: "user",
          chatId: tempChat.id,
        },
      });

      // UtwÃ³rz rekord w bazie danych
      const attachment = await prisma.attachment.create({
        data: {
          url: `/uploads/${file.filename}`,
          filename: file.originalname,
          mimetype: file.mimetype,
          size: file.size,
          messageId: tempMessage.id,
        },
      });

      console.log("âœ… Plik przesÅ‚any:", {
        id: attachment.id,
        filename: attachment.filename,
        size: formatFileSize(attachment.size),
      });

      res.json({
        id: attachment.id,
        url: attachment.url,
        filename: attachment.filename,
        mimetype: attachment.mimetype,
        size: attachment.size,
        formattedSize: formatFileSize(attachment.size),
      });
    } catch (error: any) {
      console.error("âŒ BÅ‚Ä…d przesyÅ‚ania pliku:", error);

      // UsuÅ„ plik w przypadku bÅ‚Ä™du
      const file = (req as any).file;
      if (file && fileExists(file.path)) {
        try {
          await deleteFile(file.path);
        } catch (deleteError) {
          console.error("âŒ BÅ‚Ä…d usuwania pliku po bÅ‚Ä™dzie:", deleteError);
        }
      }

      res.status(500).json({ error: "BÅ‚Ä…d podczas przesyÅ‚ania pliku" });
    }
  });
});

// Endpoint do usuwania plikÃ³w
app.delete("/api/files/:fileId", async (req: Request, res: Response) => {
  const { fileId } = req.params;

  try {
    // ZnajdÅº plik w bazie danych
    const attachment = await prisma.attachment.findUnique({
      where: { id: fileId },
    });

    if (!attachment) {
      return res.status(404).json({ error: "Plik nie zostaÅ‚ znaleziony" });
    }

    // UsuÅ„ plik z dysku
    const filePath = path.join(
      __dirname,
      "../uploads",
      path.basename(attachment.url)
    );
    if (fileExists(filePath)) {
      await deleteFile(filePath);
    }

    // UsuÅ„ rekord z bazy danych
    await prisma.attachment.delete({
      where: { id: fileId },
    });

    console.log("âœ… Plik usuniÄ™ty:", attachment.filename);
    res.json({ message: "Plik zostaÅ‚ usuniÄ™ty" });
  } catch (error: any) {
    console.error("âŒ BÅ‚Ä…d usuwania pliku:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas usuwania pliku" });
  }
});

// Prosty endpoint do czatu z AI - bez pamiÄ™ci wektorowej
app.post("/api/ai/chat", async (req: Request, res: Response) => {
  const {
    userId,
    modelId,
    userMessage,
    chatId,
    apiKey,
    provider,
    attachments,
  } = req.body;

  if (!userId || !modelId || !userMessage) {
    return res.status(400).json({
      error: "userId, modelId i userMessage sÄ… wymagane",
    });
  }

  // Walidacja klucza API w zaleÅ¼noÅ›ci od dostawcy
  if (!apiKey) {
    return res.status(400).json({
      error: `Brak klucza API dla dostawcy ${
        provider || "nieznany"
      }. ProszÄ™ skonfigurowaÄ‡ klucz API.`,
    });
  }

  try {
    let currentChatId = chatId;
    let chatTitle = "";

    // JeÅ›li nie ma chatId, utwÃ³rz nowy czat
    if (!currentChatId) {
      chatTitle =
        userMessage.length > 50
          ? userMessage.substring(0, 50) + "..."
          : userMessage;

      const newChat = await prisma.chat.create({
        data: {
          title: chatTitle,
          metadata: {
            modelId,
            isAIChat: true,
          },
        } as any,
      });

      currentChatId = newChat.id;
      console.log("âœ… Utworzono nowy czat AI:", currentChatId);
    }

    // Zapisz wiadomoÅ›Ä‡ uÅ¼ytkownika
    const userMessageRecord = await prisma.message.create({
      data: {
        content: userMessage,
        senderType: "user",
        chatId: currentChatId,
      },
    });

    // JeÅ›li sÄ… zaÅ‚Ä…czniki, zaktualizuj je aby wskazywaÅ‚y na nowÄ… wiadomoÅ›Ä‡
    if (attachments && attachments.length > 0) {
      const attachmentIds = attachments.map((att: any) => att.id);

      // Zaktualizuj zaÅ‚Ä…czniki aby wskazywaÅ‚y na nowÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika
      await prisma.attachment.updateMany({
        where: { id: { in: attachmentIds } },
        data: { messageId: userMessageRecord.id },
      });

      // UsuÅ„ tymczasowe wiadomoÅ›ci (opcjonalne - dla porzÄ…dku)
      const tempMessageIds = await prisma.attachment.findMany({
        where: { id: { in: attachmentIds } },
        select: { messageId: true },
      });

      const uniqueTempMessageIds = [
        ...new Set(tempMessageIds.map((att) => att.messageId)),
      ];

      // SprawdÅº czy to sÄ… tymczasowe wiadomoÅ›ci i usuÅ„ je
      for (const messageId of uniqueTempMessageIds) {
        if (!messageId) continue;

        const message = await prisma.message.findUnique({
          where: { id: messageId },
          include: { attachments: true },
        });

        if (
          message &&
          message.content.startsWith("[TEMP_ATTACHMENT_") &&
          (message as any).attachments.length === 0
        ) {
          await prisma.message.delete({
            where: { id: messageId },
          });
        }
      }

      console.log(
        `âœ… Zaktualizowano ${attachmentIds.length} zaÅ‚Ä…cznikÃ³w dla wiadomoÅ›ci ${userMessageRecord.id}`
      );
    }

    // Generuj prostÄ… odpowiedÅº AI bez pamiÄ™ci wektorowej
    let aiResponse = "";

    try {
      console.log("ğŸ¤– Generowanie odpowiedzi AI:", {
        chatId: currentChatId,
        provider: provider,
        modelId: modelId,
      });

      // Nowa implementacja z pamiÄ™ciÄ… wektorowÄ…
      aiResponse = await generateAIResponseWithMemory(
        userMessage,
        provider,
        apiKey,
        modelId,
        userId,
        currentChatId,
        attachments
      );

      if (!aiResponse || !aiResponse.trim()) {
        aiResponse = "Przepraszam, nie udaÅ‚o mi siÄ™ wygenerowaÄ‡ odpowiedzi.";
      }
    } catch (aiError: any) {
      console.error(
        "âŒ BÅ‚Ä…d podczas generowania odpowiedzi AI:",
        aiError.message
      );

      return res.status(500).json({
        error: "BÅ‚Ä…d podczas generowania odpowiedzi AI. SprawdÅº klucz API.",
      });
    }

    // Zapisz odpowiedÅº AI
    const aiMessageRecord = await prisma.message.create({
      data: {
        content: aiResponse,
        senderType: "ai",
        chatId: currentChatId,
      },
    });

    // Zapisz wiadomoÅ›ci do pamiÄ™ci wektorowej (asynchronicznie)
    if (vectorMemoryService.isReady()) {
      // Pobierz kontekst (kilka poprzednich wiadomoÅ›ci)
      const recentMessages = await prisma.message.findMany({
        where: { chatId: currentChatId },
        orderBy: { createdAt: 'desc' },
        take: 3
        // No need for sender include in single user mode
      });
      
      const context = recentMessages
        .reverse()
        .map(msg => `${msg.senderType === 'user' ? 'User' : 'AI'}: ${msg.content}`)
        .join('\n');

      // Zapisz wiadomoÅ›Ä‡ uÅ¼ytkownika do pamiÄ™ci (asynchronicznie)
      vectorMemoryService.addMemoryEntry(
        userMessage,
        currentChatId,
        userMessageRecord.id,
        context
      ).catch(error => {
        console.error('âŒ BÅ‚Ä…d zapisywania wiadomoÅ›ci uÅ¼ytkownika do pamiÄ™ci:', error);
      });

      // Zapisz odpowiedÅº AI do pamiÄ™ci jako czÄ™Å›Ä‡ konwersacji uÅ¼ytkownika (asynchronicznie)
      vectorMemoryService.addMemoryEntry(
        `AI odpowiedziaÅ‚: ${aiResponse}`, // Oznacz Å¼e to odpowiedÅº AI
        currentChatId,
        aiMessageRecord.id,
        context
      ).catch(error => {
        console.error('âŒ BÅ‚Ä…d zapisywania odpowiedzi AI do pamiÄ™ci:', error);
      });
    }

    // Zaktualizuj czas ostatniej modyfikacji czatu
    await prisma.chat.update({
      where: { id: currentChatId },
      data: { updatedAt: new Date() },
    });

    console.log("âœ… OdpowiedÅº AI wygenerowana:", {
      responseLength: aiResponse.length,
      chatId: currentChatId,
      provider: provider,
      memoryEnabled: vectorMemoryService.isReady()
    });

    res.json({
      response: aiResponse,
      modelId,
      chatId: currentChatId,
      chatTitle: chatTitle || undefined,
    });
  } catch (error: any) {
    console.error("âŒ BÅ‚Ä…d przetwarzania Å¼Ä…dania AI:", error.message);
    res.status(500).json({
      error: "WystÄ…piÅ‚ bÅ‚Ä…d podczas przetwarzania Å¼Ä…dania AI",
    });
  }
});

// --- Endpointy do zarzÄ…dzania pamiÄ™ciÄ… wektorowÄ… ---

// TESTOWY endpoint do rÄ™cznego sprawdzenia pamiÄ™ci
app.post("/api/memory/test", async (req: Request, res: Response) => {
  const { content } = req.body;

  if (!content) {
    return res.status(400).json({ error: "content jest wymagany" });
  }

  try {
    console.log(`ğŸ§ª TEST: DodajÄ™ do pamiÄ™ci: "${content}"`);
    
    if (vectorMemoryService.isReady()) {
      const result = await vectorMemoryService.addMemoryEntry(
        content,
        "test-chat",
        undefined,
        "Test context"
      );
      
      res.json({ 
        success: true, 
        result,
        message: "Wpis dodany do pamiÄ™ci" 
      });
    } else {
      res.json({ 
        success: false, 
        message: "Serwis pamiÄ™ci wektorowej nie jest gotowy" 
      });
    }
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d testu pamiÄ™ci:", error);
    res.status(500).json({ error: "BÅ‚Ä…d testu pamiÄ™ci" });
  }
});

// Endpoint do wyszukiwania w pamiÄ™ci
app.post("/api/memory/search", async (req: Request, res: Response) => {
  const { query, chatId, limit = 10, minImportance = 0.3 } = req.body;

  if (!query) {
    return res.status(400).json({ error: "query jest wymagany" });
  }

  if (!vectorMemoryService.isReady()) {
    return res.status(503).json({ error: "Serwis pamiÄ™ci wektorowej nie jest gotowy" });
  }

  try {
    const results = await vectorMemoryService.searchMemory(query, {
      chatId,
      limit,
      minImportance
    });

    res.json({ results, count: results.length });
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d wyszukiwania w pamiÄ™ci:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas wyszukiwania w pamiÄ™ci" });
  }
});

// Endpoint do czyszczenia pamiÄ™ci (stare wpisy)
app.delete("/api/memory/cleanup", async (req: Request, res: Response) => {
  if (!vectorMemoryService.isReady()) {
    return res.status(503).json({ error: "Serwis pamiÄ™ci wektorowej nie jest gotowy" });
  }

  try {
    const deletedCount = await vectorMemoryService.cleanupMemory();
    res.json({ message: `Wyczyszczono ${deletedCount} starych wpisÃ³w z pamiÄ™ci`, deletedCount });
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d czyszczenia pamiÄ™ci:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas czyszczenia pamiÄ™ci" });
  }
});

// Endpoint do usuwania pamiÄ™ci konkretnego czatu
app.delete("/api/memory/chat/:chatId", async (req: Request, res: Response) => {
  const { chatId } = req.params;

  if (!vectorMemoryService.isReady()) {
    return res.status(503).json({ error: "Serwis pamiÄ™ci wektorowej nie jest gotowy" });
  }

  try {
    const deletedCount = await vectorMemoryService.deleteMemoryByChat(chatId);
    res.json({ 
      message: `UsuniÄ™to pamiÄ™Ä‡ z czatu ${chatId}`, 
      deletedCount,
      chatId 
    });
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d usuwania pamiÄ™ci czatu:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas usuwania pamiÄ™ci czatu" });
  }
});

// Endpoint do usuwania pamiÄ™ci konkretnej wiadomoÅ›ci
app.delete("/api/memory/message/:messageId", async (req: Request, res: Response) => {
  const { messageId } = req.params;

  if (!vectorMemoryService.isReady()) {
    return res.status(503).json({ error: "Serwis pamiÄ™ci wektorowej nie jest gotowy" });
  }

  try {
    const deletedCount = await vectorMemoryService.deleteMemoryByMessage(messageId);
    res.json({ 
      message: `UsuniÄ™to pamiÄ™Ä‡ wiadomoÅ›ci ${messageId}`, 
      deletedCount,
      messageId 
    });
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d usuwania pamiÄ™ci wiadomoÅ›ci:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas usuwania pamiÄ™ci wiadomoÅ›ci" });
  }
});

// Endpoint do usuwania caÅ‚ej pamiÄ™ci (single user mode)
app.delete("/api/memory/all", async (req: Request, res: Response) => {
  const { confirm } = req.body; // Dodatkowa weryfikacja

  if (!confirm || confirm !== 'DELETE_ALL_MEMORY') {
    return res.status(400).json({ error: "Potwierdzenie 'DELETE_ALL_MEMORY' jest wymagane" });
  }

  if (!vectorMemoryService.isReady()) {
    return res.status(503).json({ error: "Serwis pamiÄ™ci wektorowej nie jest gotowy" });
  }

  try {
    const deletedCount = await vectorMemoryService.deleteAllMemory();
    res.json({ 
      message: `UsuniÄ™to caÅ‚Ä… pamiÄ™Ä‡`, 
      deletedCount
    });
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d usuwania pamiÄ™ci:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas usuwania pamiÄ™ci" });
  }
});

// Endpoint do eksportu pamiÄ™ci (single user mode)
app.get("/api/memory/export", async (req: Request, res: Response) => {
  try {
    const memoryEntries = await prisma.vectorMemory.findMany({
      orderBy: { timestamp: 'desc' },
      select: {
        id: true,
        content: true,
        importanceScore: true,
        timestamp: true,
        tags: true,
        context: true,
        metadata: true
      }
    });

    const exportData = {
      exportDate: new Date().toISOString(),
      entriesCount: memoryEntries.length,
      entries: memoryEntries
    };

    res.setHeader('Content-Type', 'application/json');
    res.setHeader('Content-Disposition', `attachment; filename="memory-export-${Date.now()}.json"`);
    res.json(exportData);
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d eksportu pamiÄ™ci:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas eksportu pamiÄ™ci" });
  }
});

// Endpoint do statystyk pamiÄ™ci (single user mode)
app.get("/api/memory/stats", async (req: Request, res: Response) => {
  try {
    if (vectorMemoryService.isReady()) {
      // UÅ¼yj nowej metody z VectorMemoryService
      const stats = await vectorMemoryService.getMemoryStats();
      res.json({
        ...stats,
        memoryServiceReady: true
      });
    } else {
      // Fallback - podstawowe statystyki z Prisma
      const totalEntries = await prisma.vectorMemory.count();
      
      const averageImportance = await prisma.vectorMemory.aggregate({
        _avg: { importanceScore: true }
      });

      res.json({
        totalEntries,
        averageImportance: averageImportance._avg.importanceScore || 0,
        entriesByChat: [],
        topTags: [],
        oldestEntry: null,
        newestEntry: null,
        memoryServiceReady: false
      });
    }
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d pobierania statystyk pamiÄ™ci:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas pobierania statystyk pamiÄ™ci" });
  }
});

// Endpoint do weryfikacji spÃ³jnoÅ›ci pamiÄ™ci
app.post("/api/memory/validate", async (req: Request, res: Response) => {
  if (!vectorMemoryService.isReady()) {
    return res.status(503).json({ error: "Serwis pamiÄ™ci wektorowej nie jest gotowy" });
  }

  try {
    console.log(`ğŸ” Rozpoczynam weryfikacjÄ™ spÃ³jnoÅ›ci pamiÄ™ci`);
    
    const validationStats = await vectorMemoryService.validateMemoryConsistency();
    
    res.json({
      message: "Weryfikacja spÃ³jnoÅ›ci zakoÅ„czona",
      stats: validationStats
    });
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d weryfikacji spÃ³jnoÅ›ci pamiÄ™ci:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas weryfikacji spÃ³jnoÅ›ci pamiÄ™ci" });
  }
});

// Endpoint do ustawieÅ„ pamiÄ™ci uÅ¼ytkownika (single user mode)
app.get("/api/memory/settings", async (req: Request, res: Response) => {
  try {
    let settings = await prisma.memorySettings.findFirst();

    if (!settings) {
      // UtwÃ³rz domyÅ›lne ustawienia
      settings = await prisma.memorySettings.create({
        data: {}
      });
    }

    res.json(settings);
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d pobierania ustawieÅ„ pamiÄ™ci:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas pobierania ustawieÅ„ pamiÄ™ci" });
  }
});

// Endpoint do aktualizacji ustawieÅ„ pamiÄ™ci (single user mode)
app.put("/api/memory/settings", async (req: Request, res: Response) => {
  const { 
    importanceThreshold, 
    maxMemoryEntries, 
    retentionDays, 
    autoCleanupEnabled,
    memoryEnabled,
    autoDeleteOnChatRemoval,
    incognitoMode,
    shareMemoryAcrossChats,
    memoryAggressiveness
  } = req.body;

  try {
    // Find existing settings or create new ones
    let settings = await prisma.memorySettings.findFirst();
    
    if (settings) {
      // Update existing settings
      settings = await prisma.memorySettings.update({
        where: { id: settings.id },
        data: {
          ...(importanceThreshold !== undefined && { importanceThreshold }),
          ...(maxMemoryEntries !== undefined && { maxMemoryEntries }),
          ...(retentionDays !== undefined && { retentionDays }),
          ...(autoCleanupEnabled !== undefined && { autoCleanupEnabled }),
          ...(memoryEnabled !== undefined && { memoryEnabled }),
          ...(autoDeleteOnChatRemoval !== undefined && { autoDeleteOnChatRemoval }),
          ...(incognitoMode !== undefined && { incognitoMode }),
          ...(shareMemoryAcrossChats !== undefined && { shareMemoryAcrossChats }),
          ...(memoryAggressiveness !== undefined && { memoryAggressiveness }),
          updatedAt: new Date()
        }
      });
    } else {
      // Create new settings
      settings = await prisma.memorySettings.create({
        data: {
          importanceThreshold: importanceThreshold || 0.3,
          maxMemoryEntries: maxMemoryEntries || 10000,
          retentionDays: retentionDays || 365,
          autoCleanupEnabled: autoCleanupEnabled !== undefined ? autoCleanupEnabled : true,
          memoryEnabled: memoryEnabled !== undefined ? memoryEnabled : true,
          autoDeleteOnChatRemoval: autoDeleteOnChatRemoval !== undefined ? autoDeleteOnChatRemoval : true,
          incognitoMode: incognitoMode !== undefined ? incognitoMode : false,
          shareMemoryAcrossChats: shareMemoryAcrossChats !== undefined ? shareMemoryAcrossChats : true,
          memoryAggressiveness: memoryAggressiveness || 'conservative'
        }
      });
    }

    console.log(`âš™ï¸ Zaktualizowano ustawienia pamiÄ™ci`);
    res.json(settings);
  } catch (error) {
    console.error("âŒ BÅ‚Ä…d aktualizacji ustawieÅ„ pamiÄ™ci:", error);
    res.status(500).json({ error: "BÅ‚Ä…d podczas aktualizacji ustawieÅ„ pamiÄ™ci" });
  }
});

// --- Uruchomienie serwera i obsÅ‚uga zamykania ---

const PORT = process.env.PORT || 3001;
app.listen(PORT, async () => {
  console.log(`ğŸš€ Server is running at http://localhost:${PORT}`);
  // Initialize vector memory service
  await initializeVectorMemory();
});

const gracefulShutdown = async (signal: string) => {
  console.log(`Received ${signal}. Shutting down gracefully...`);
  await prisma.$disconnect();
  console.log("Prisma Client disconnected.");
  process.exit(0);
};

process.on("SIGINT", () => gracefulShutdown("SIGINT"));
process.on("SIGTERM", () => gracefulShutdown("SIGTERM"));
