import { pipeline, env } from '@xenova/transformers';

// WyÅ‚Ä…cz lokalne modele - uÅ¼ywamy tylko cache
env.allowLocalModels = false;

interface EmbeddingResult {
  embedding: number[];
  error?: string;
}

class EmbeddingsService {
  private static instance: EmbeddingsService;
  private embeddingPipeline: any = null;
  private isInitialized = false;

  private constructor() {}

  public static getInstance(): EmbeddingsService {
    if (!EmbeddingsService.instance) {
      EmbeddingsService.instance = new EmbeddingsService();
    }
    return EmbeddingsService.instance;
  }

  /**
   * Inicjalizuje pipeline do generowania embeddings
   * UÅ¼ywa modelu sentence-transformers/all-MiniLM-L6-v2 (384 wymiary)
   */
  public async initialize(): Promise<void> {
    if (this.isInitialized) return;

    try {
      console.log('ğŸ§  Inicjalizacja EmbeddingsService...');
      
      // UÅ¼ywamy lekkiego modelu dla szybkoÅ›ci
      this.embeddingPipeline = await pipeline(
        'feature-extraction', 
        'Xenova/all-MiniLM-L6-v2',
        { 
          progress_callback: (progress: any) => {
            if (progress.status === 'download') {
              console.log(`â¬‡ï¸ Pobieranie modelu: ${Math.round(progress.progress)}%`);
            }
          }
        }
      );
      
      this.isInitialized = true;
      console.log('âœ… EmbeddingsService zainicjalizowany');
    } catch (error) {
      console.error('âŒ BÅ‚Ä…d inicjalizacji EmbeddingsService:', error);
      throw new Error('Nie udaÅ‚o siÄ™ zainicjalizowaÄ‡ generatora embeddings');
    }
  }

  /**
   * Generuje wektor embeddings dla danego tekstu
   */
  public async generateEmbedding(text: string): Promise<EmbeddingResult> {
    if (!this.isInitialized) {
      await this.initialize();
    }

    if (!text || text.trim().length === 0) {
      return { 
        embedding: [], 
        error: 'Pusty tekst' 
      };
    }

    try {
      // Ogranicz dÅ‚ugoÅ›Ä‡ tekstu (modele majÄ… limity tokenÃ³w)
      const truncatedText = text.length > 1000 ? text.substring(0, 1000) : text;
      
      // Generuj embedding
      const output = await this.embeddingPipeline(truncatedText, {
        pooling: 'mean',
        normalize: true,
      });

      // WyciÄ…gnij wektor z rezultatu
      const embedding = Array.from(output.data) as number[];
      
      console.log(`ğŸ§  Wygenerowano embedding (${embedding.length} wymiarÃ³w) dla tekstu o dÅ‚ugoÅ›ci ${text.length}`);
      
      return { embedding };
    } catch (error) {
      console.error('âŒ BÅ‚Ä…d generowania embedding:', error);
      return { 
        embedding: [], 
        error: `BÅ‚Ä…d generowania embedding: ${error}` 
      };
    }
  }

  /**
   * Generuje embeddings dla wielu tekstÃ³w jednoczeÅ›nie (batch processing)
   */
  public async generateBatchEmbeddings(texts: string[]): Promise<EmbeddingResult[]> {
    if (!this.isInitialized) {
      await this.initialize();
    }

    const results: EmbeddingResult[] = [];
    
    // Przetwarzaj w maÅ‚ych batchach Å¼eby nie przeciÄ…Å¼yÄ‡ pamiÄ™ci
    const batchSize = 5;
    
    for (let i = 0; i < texts.length; i += batchSize) {
      const batch = texts.slice(i, i + batchSize);
      const batchPromises = batch.map(text => this.generateEmbedding(text));
      const batchResults = await Promise.all(batchPromises);
      results.push(...batchResults);
    }

    return results;
  }

  /**
   * Oblicza podobieÅ„stwo kosinusowe miÄ™dzy dwoma wektorami
   */
  public static cosineSimilarity(vectorA: number[], vectorB: number[]): number {
    if (vectorA.length !== vectorB.length) {
      throw new Error('Wektory muszÄ… mieÄ‡ tÄ™ samÄ… dÅ‚ugoÅ›Ä‡');
    }

    let dotProduct = 0;
    let normA = 0;
    let normB = 0;

    for (let i = 0; i < vectorA.length; i++) {
      dotProduct += vectorA[i] * vectorB[i];
      normA += vectorA[i] * vectorA[i];
      normB += vectorB[i] * vectorB[i];
    }

    const magnitude = Math.sqrt(normA) * Math.sqrt(normB);
    
    if (magnitude === 0) return 0;
    
    return dotProduct / magnitude;
  }

  /**
   * Znajduje najbardziej podobne wektory do query
   */
  public static findMostSimilar(
    queryEmbedding: number[], 
    candidateEmbeddings: { id: string; embedding: number[]; }[],
    topK: number = 5
  ): { id: string; similarity: number; }[] {
    
    const similarities = candidateEmbeddings.map(candidate => ({
      id: candidate.id,
      similarity: EmbeddingsService.cosineSimilarity(queryEmbedding, candidate.embedding)
    }));

    // Sortuj malejÄ…co po podobieÅ„stwie
    similarities.sort((a, b) => b.similarity - a.similarity);
    
    return similarities.slice(0, topK);
  }

  /**
   * Sprawdza czy serwis jest gotowy do uÅ¼ycia
   */
  public isReady(): boolean {
    return this.isInitialized && this.embeddingPipeline !== null;
  }
}

export default EmbeddingsService;