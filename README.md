# MyLLM Chat

**Nowoczesna aplikacja czatowa z AI** - alternatywa dla ChatGPT, Gemini i Claude z moÅ¼liwoÅ›ciÄ… uÅ¼ywania wÅ‚asnych kluczy API zamiast pÅ‚acenia abonamentÃ³w.

![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)
![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB)
![Node.js](https://img.shields.io/badge/Node.js-43853D?style=for-the-badge&logo=node.js&logoColor=white)
![Electron](https://img.shields.io/badge/Electron-2B2E3A?style=for-the-badge&logo=electron&logoColor=9FEAF9)
![Prisma](https://img.shields.io/badge/Prisma-3982CE?style=for-the-badge&logo=Prisma&logoColor=white)
![SQLite](https://img.shields.io/badge/SQLite-07405e?style=for-the-badge&logo=sqlite&logoColor=white)

## ğŸ“¥ Pobierz aplikacjÄ™ desktop

### Najnowsza wersja: [Releases](https://github.com/your-username/myllm-chat/releases)

#### Windows ğŸªŸ
- **[ğŸ“¦ MyLLM-Chat-Setup.exe](https://github.com/your-username/myllm-chat/releases/latest)** - Installer NSIS
- **[ğŸ“¦ MyLLM-Chat.msi](https://github.com/your-username/myllm-chat/releases/latest)** - Installer MSI
- **Wymagania**: Windows 10/11 (64-bit)

#### macOS ğŸ  
- **[ğŸ“¦ MyLLM-Chat.dmg](https://github.com/your-username/myllm-chat/releases/latest)** - Disk Image
- **[ğŸ“¦ MyLLM-Chat.pkg](https://github.com/your-username/myllm-chat/releases/latest)** - Package Installer
- **Wymagania**: macOS 10.15+ (Intel/Apple Silicon)

#### Linux ğŸ§
- **[ğŸ“¦ MyLLM-Chat.AppImage](https://github.com/your-username/myllm-chat/releases/latest)** - Portable AppImage
- **[ğŸ“¦ MyLLM-Chat.deb](https://github.com/your-username/myllm-chat/releases/latest)** - Debian/Ubuntu Package
- **Wymagania**: Ubuntu 18.04+ / Debian 10+

### ğŸš€ Szybki start
1. Pobierz installer dla swojego systemu
2. Uruchom plik i postÄ™puj zgodnie z instrukcjami
3. OtwÃ³rz aplikacjÄ™ i skonfiguruj klucze API
4. Rozpocznij chatowanie z AI!

### ğŸ“± Instalacja

#### Windows ğŸªŸ
1. Pobierz `.exe` lub `.msi` z [Releases](https://github.com/your-username/myllm-chat/releases)
2. Uruchom installer jako administrator (jeÅ›li Windows wymaga)
3. JeÅ›li Windows SmartScreen zablokuje: kliknij "More info" â†’ "Run anyway"
4. PostÄ™puj zgodnie z kreatorem instalacji

#### macOS ğŸ
1. Pobierz `.dmg` z [Releases](https://github.com/your-username/myllm-chat/releases)
2. OtwÃ³rz plik `.dmg` i przeciÄ…gnij MyLLM Chat do Applications
3. Przy pierwszym uruchomieniu: kliknij prawym â†’ "Open" (obejÅ›cie Gatekeeper)
4. Lub w System Preferences â†’ Security â†’ "Open Anyway"

#### Linux ğŸ§
**AppImage (zalecane)**:
```bash
chmod +x MyLLM-Chat-*.AppImage
./MyLLM-Chat-*.AppImage
```

**Debian/Ubuntu**:
```bash
sudo dpkg -i MyLLM-Chat_*.deb
sudo apt-get install -f  # jeÅ›li brakuje zaleÅ¼noÅ›ci
```

## ğŸ“– Opis projektu

MyLLM Chat to nowoczesna aplikacja webowa umoÅ¼liwiajÄ…ca konwersacje z rÃ³Å¼nymi modelami AI. Projekt powstaÅ‚ jako alternatywa dla popularnych chatbotÃ³w AI (ChatGPT, Gemini, Claude), z kluczowÄ… rÃ³Å¼nicÄ… - **uÅ¼ywasz wÅ‚asnych kluczy API** zamiast pÅ‚acenia miesiÄ™cznych abonamentÃ³w.

### ğŸ¯ GÅ‚Ã³wne cele projektu

- **OszczÄ™dnoÅ›Ä‡** - pÅ‚acisz tylko za rzeczywiste uÅ¼ycie API
- **PrywatnoÅ›Ä‡** - klucze API przechowywane lokalnie w przeglÄ…darce
- **ElastycznoÅ›Ä‡** - wybÃ³r spoÅ›rÃ³d rÃ³Å¼nych modeli AI w jednym miejscu
- **NowoczesnoÅ›Ä‡** - responsywny design i intuicyjny interfejs

## âœ¨ FunkcjonalnoÅ›ci

### ğŸ¤– Modele AI

- **Google Gemini** (2.5 Flash, 2.5 Pro)
- **OpenAI GPT** (GPT-4.1)
- **Anthropic Claude** (Claude 4 Sonnet)
- Åatwe przeÅ‚Ä…czanie miÄ™dzy modelami w trakcie konwersacji

### ğŸ’¬ ZarzÄ…dzanie czatami

- Tworzenie i usuwanie rozmÃ³w
- Historia wszystkich konwersacji
- Automatyczne generowanie tytuÅ‚Ã³w czatÃ³w
- Sidebar z listÄ… ostatnich rozmÃ³w

### ğŸ§  PamiÄ™Ä‡ wektorowa (NOWOÅšÄ†!)

- **Inteligentna pamiÄ™Ä‡ miÄ™dzy rozmowami** - AI pamiÄ™ta informacje z poprzednich czatÃ³w
- **Semantyczne wyszukiwanie** - znajdowanie podobnych tematÃ³w z historii
- **Automatyczna ocena waÅ¼noÅ›ci** - zapisywanie tylko istotnych informacji
- **Inteligentna analiza intencji** - rozrÃ³Å¼nianie kontynuacji tematu od odwoÅ‚aÅ„ do przeszÅ‚oÅ›ci
- **Konfigurowane ustawienia prywatnoÅ›ci** - peÅ‚na kontrola nad tym co jest zapisywane
- **Tryb incognito** - rozmowy bez zapisywania do pamiÄ™ci

### ğŸ“ ObsÅ‚uga plikÃ³w

- PrzesyÅ‚anie i analiza dokumentÃ³w (PDF, DOCX, XLSX)
- ObsÅ‚uga obrazÃ³w (JPEG, PNG, GIF, WebP)
- Pliki tekstowe (TXT, CSV, JSON)
- Maksymalny rozmiar pliku: 10MB

### ğŸ” BezpieczeÅ„stwo

- System rejestracji i logowania
- Hashowanie haseÅ‚ (bcrypt)
- Lokalne przechowywanie kluczy API
- Ochrona tras przed nieautoryzowanym dostÄ™pem

### ğŸ¨ Interfejs uÅ¼ytkownika

- Responsywny design (desktop + mobile)
- Ciemny sidebar z jasnymi okienkami czatu
- Markdown rendering z podÅ›wietlaniem skÅ‚adni
- Animacje i smooth scrolling
- Toast notifications

## ğŸ› ï¸ Technologie

### Frontend

- **React 19** - nowoczesna biblioteka UI
- **TypeScript** - statyczne typowanie
- **Vite** - szybki bundler
- **Chakra UI v3** - komponenty UI
- **React Router v7** - routing
- **React Markdown** - renderowanie markdown z KaTeX i syntax highlighting
- **React Toastify** - notyfikacje
- **Tailwind CSS** - stylowanie

### Backend

- **Node.js** - Å›rodowisko runtime
- **Express** - framework webowy
- **TypeScript** - statyczne typowanie
- **Prisma** - ORM i migracje bazy danych
- **PostgreSQL** - baza danych
- **bcrypt** - hashowanie haseÅ‚
- **Multer** - obsÅ‚uga plikÃ³w
- **CORS** - obsÅ‚uga cross-origin requests

### Integracje AI

- **@google/generative-ai** - Google Gemini
- **openai** - OpenAI GPT
- **@anthropic-ai/sdk** - Anthropic Claude
- **@xenova/transformers** - lokalne generowanie embeddings dla pamiÄ™ci wektorowej

### ObsÅ‚uga plikÃ³w

- **pdf-parse** - parsowanie PDF
- **mammoth** - konwersja DOCX
- **xlsx** - obsÅ‚uga arkuszy Excel

## ğŸš€ Instalacja i uruchomienie

### Wymagania systemowe

- **Node.js** 18+
- **npm** lub **yarn**
- **PostgreSQL** 12+

### 1. Klonowanie repozytorium

```bash
git clone https://github.com/twoje-username/myllm-chat.git
cd myllm-chat
```

### 2. Instalacja zaleÅ¼noÅ›ci

```bash
# Instalacja dla caÅ‚ego projektu (workspace)
npm install

# Lub osobno dla kaÅ¼dego moduÅ‚u
cd client && npm install
cd ../server && npm install
```

### 3. Konfiguracja bazy danych

#### UtwÃ³rz bazÄ™ PostgreSQL

```sql
CREATE DATABASE myllm_chat;
CREATE USER myllm_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE myllm_chat TO myllm_user;
```

#### Skonfiguruj zmiennÄ… Å›rodowiskowÄ…

UtwÃ³rz plik `server/.env`:

```env
DATABASE_URL="postgresql://myllm_user:your_password@localhost:5432/myllm_chat"
```

### 4. Migracja bazy danych

```bash
cd server
npx prisma migrate deploy
npx prisma generate
```

### 5. Uruchomienie aplikacji

#### Opcja 1: Wszystko naraz (zalecane)

```bash
# Z gÅ‚Ã³wnego katalogu
npm run dev
```

#### Opcja 2: Osobno

```bash
# Terminal 1 - Backend
cd server
npm run dev

# Terminal 2 - Frontend
cd client
npm run dev
```

### 6. DostÄ™p do aplikacji

- **Frontend**: http://localhost:5173
- **Backend**: http://localhost:3001

## ğŸ–¥ï¸ Budowanie aplikacji desktop

### Wymagania dla budowania
- **Node.js** 18+
- **npm** 8+
- **Wszystkie zaleÅ¼noÅ›ci** zainstalowane (root + workspaces)

### Szybkie budowanie

#### Windows (.exe + .msi)
```bash
npm run release:build:win
```

#### macOS (.dmg + .pkg)  
```bash
npm run release:build:mac
```

#### Linux (.AppImage + .deb)
```bash
npm run release:build:linux
```

#### Wszystkie platformy
```bash
npm run release:build:all
```

### Pliki wyjÅ›ciowe
Wszystkie zbudowane instalatory znajdziesz w: `electron/release/`

### Czyszczenie przed buildem
```bash
npm run release:clean
npm run release:test
```

### Workflow manual release
1. **Przygotuj wersjÄ™**:
   ```bash
   npm run release:clean
   npm run release:test
   ```

2. **Zbuduj instalatory**:
   ```bash
   npm run release:build:all
   ```

3. **SprawdÅº wyniki** w `electron/release/`:
   - `MyLLM-Chat-Setup-1.0.0.exe` (Windows NSIS)
   - `MyLLM-Chat-1.0.0.msi` (Windows MSI)
   - `MyLLM-Chat-1.0.0.dmg` (macOS)
   - `MyLLM-Chat-1.0.0.pkg` (macOS)
   - `MyLLM-Chat-1.0.0.AppImage` (Linux)
   - `MyLLM-Chat_1.0.0_amd64.deb` (Linux)

4. **UtwÃ³rz GitHub Release**:
   - IdÅº na GitHub â†’ Releases â†’ "Create new release"
   - Tag: `v1.0.0` (nowa wersja)
   - TytuÅ‚: `MyLLM Chat v1.0.0`
   - Opis: Opisz zmiany w tej wersji
   - ZaÅ‚Ä…cz wszystkie pliki z `electron/release/`
   - Kliknij "Publish release"

### Troubleshooting budowania

#### Windows
- Zainstaluj **Windows Build Tools**: `npm install -g windows-build-tools`
- MoÅ¼e potrzebowaÄ‡ **Visual Studio Build Tools**

#### macOS  
- Zainstaluj **Xcode Command Line Tools**: `xcode-select --install`
- MoÅ¼e potrzebowaÄ‡ **Apple Developer Certificate** do signing

#### Linux
- Zainstaluj pakiety build: `sudo apt-get install build-essential libnss3-dev libatk-bridge2.0-dev libgtk-3-dev libxss1`

## ğŸ”‘ Konfiguracja kluczy API

Po uruchomieniu aplikacji:

1. **Zarejestruj siÄ™** lub zaloguj w aplikacji
2. **Kliknij ikonÄ™ koÅ‚a zÄ™batego** w sidebarze
3. **Dodaj klucze API** dla wybranych dostawcÃ³w:

### Google Gemini

- PrzejdÅº do [Google Cloud Console](https://console.cloud.google.com)
- WÅ‚Ä…cz Generative AI API
- UtwÃ³rz klucz API
- Format: `AIza...`

### OpenAI

- PrzejdÅº do [OpenAI Platform](https://platform.openai.com/api-keys)
- UtwÃ³rz nowy klucz API
- Format: `sk-...`

### Anthropic Claude

- PrzejdÅº do [Anthropic Console](https://console.anthropic.com)
- UtwÃ³rz klucz API
- Format: `sk-ant-...`

## ğŸ“ Struktura projektu

```
myllm-chat/
â”œâ”€â”€ client/                 # Aplikacja React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Komponenty React
â”‚   â”‚   â”‚   â”œâ”€â”€ chatpage/   # Komponenty czatu
â”‚   â”‚   â”‚   â”œâ”€â”€ pages/      # Strony (Auth)
â”‚   â”‚   â”‚   â””â”€â”€ ui/         # Komponenty UI
â”‚   â”‚   â”œâ”€â”€ contexts/       # React Context (Auth)
â”‚   â”‚   â”œâ”€â”€ hooks/          # Custom hooks
â”‚   â”‚   â””â”€â”€ types/          # Definicje TypeScript
â”‚   â”œâ”€â”€ public/            # Statyczne pliki
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ server/                # Backend Node.js
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ services/      # Serwisy (pamiÄ™Ä‡ wektorowa, analiza intencji)
â”‚   â”‚   â”‚   â”œâ”€â”€ VectorMemoryService.ts    # GÅ‚Ã³wny serwis pamiÄ™ci
â”‚   â”‚   â”‚   â”œâ”€â”€ EmbeddingsService.ts      # Generowanie embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ ImportanceScorer.ts       # Ocena waÅ¼noÅ›ci wiadomoÅ›ci
â”‚   â”‚   â”‚   â””â”€â”€ IntentAnalyzer.ts         # Analiza intencji uÅ¼ytkownika
â”‚   â”‚   â”œâ”€â”€ utils/         # Utilities (obsÅ‚uga plikÃ³w)
â”‚   â”‚   â””â”€â”€ server.ts      # GÅ‚Ã³wny plik serwera
â”‚   â”œâ”€â”€ prisma/            # Schema i migracje bazy
â”‚   â”œâ”€â”€ uploads/           # PrzesÅ‚ane pliki
â”‚   â””â”€â”€ package.json
â””â”€â”€ package.json          # Workspace config
```

## ğŸ® Jak uÅ¼ywaÄ‡

### RozpoczÄ™cie nowej rozmowy

1. Kliknij **"Nowa rozmowa"** w sidebarze
2. Wybierz model AI z listy rozwijanej
3. Napisz wiadomoÅ›Ä‡ i wyÅ›lij

### PrzesyÅ‚anie plikÃ³w

1. Kliknij ikonÄ™ **ğŸ“** obok pola tekstowego
2. Wybierz pliki (maks. 10MB kaÅ¼dy)
3. WyÅ›lij wiadomoÅ›Ä‡ - AI przeanalizuje zaÅ‚Ä…czniki

### ZarzÄ…dzanie rozmowami

- **Usuwanie**: NajedÅº na czat w sidebarze i kliknij ikonÄ™ kosza
- **Kopiowanie**: Kliknij "Kopiuj" przy kaÅ¼dej wiadomoÅ›ci  
- **Zmiana modelu**: UÅ¼yj listy rozwijanej w obszarze czatu

### ğŸ§  Konfiguracja pamiÄ™ci wektorowej

1. **Ustawienia podstawowe** - dostÄ™p przez API `GET/PUT /api/memory/settings/:userId`
2. **Poziomy agresywnoÅ›ci pamiÄ™ci**:
   - `conservative` (domyÅ›lny) - pamiÄ™Ä‡ tylko przy wyraÅºnych odwoÅ‚aniach
   - `moderate` - pamiÄ™Ä‡ przy dwuznacznych sytuacjach
   - `aggressive` - pamiÄ™Ä‡ zawsze aktywna
3. **Opcje prywatnoÅ›ci**:
   - WyÅ‚Ä…czenie pamiÄ™ci (`memoryEnabled: false`)
   - Tryb incognito (`incognitoMode: true`)
   - Ograniczenie do pojedynczych czatÃ³w (`shareMemoryAcrossChats: false`)

### ğŸ“Š API pamiÄ™ci wektorowej

- `POST /api/memory/search` - wyszukiwanie w pamiÄ™ci
- `DELETE /api/memory/cleanup/:userId` - czyszczenie starych wpisÃ³w
- `DELETE /api/memory/chat/:chatId` - usuwanie pamiÄ™ci czatu
- `GET /api/memory/stats/:userId` - statystyki pamiÄ™ci
- `POST /api/memory/validate/:userId` - weryfikacja spÃ³jnoÅ›ci

## ğŸ› RozwiÄ…zywanie problemÃ³w

### Problemy z aplikacjÄ… desktop ğŸ–¥ï¸

#### Windows
**Windows SmartScreen blokuje aplikacjÄ™**
1. Kliknij "More info" 
2. Kliknij "Run anyway"
3. Lub wyÅ‚Ä…cz SmartScreen tymczasowo w Windows Defender

**Aplikacja nie startuje**
1. Uruchom jako administrator
2. SprawdÅº czy masz .NET Framework 4.7.2+
3. SprawdÅº logi w Event Viewer

**Antywirus usuwa aplikacjÄ™**
1. Dodaj folder aplikacji do exclusions
2. Pobierz ponownie z GitHub Releases

#### macOS
**"Application can't be opened" (Gatekeeper)**
1. Kliknij prawym na aplikacjÄ™ â†’ "Open"
2. Lub w System Preferences â†’ Security â†’ "Open Anyway"
3. Lub wyÅ‚Ä…cz Gatekeeper: `sudo spctl --master-disable`

**Aplikacja crashuje przy starcie**
1. SprawdÅº czy masz macOS 10.15+
2. SprawdÅº Console.app dla bÅ‚Ä™dÃ³w
3. SprÃ³buj wersji x64 vs arm64

#### Linux
**AppImage nie uruchamia siÄ™**
```bash
chmod +x MyLLM-Chat-*.AppImage
./MyLLM-Chat-*.AppImage
```

**Brakuje bibliotek (Ubuntu/Debian)**
```bash
sudo apt-get install libgtk-3-0 libxss1 libnss3 libgconf-2-4
```

**Problem z permissions**
```bash
sudo chmod +x MyLLM-Chat-*.AppImage
sudo chown $USER:$USER MyLLM-Chat-*.AppImage
```

### Problemy z developmentem ğŸ’»

#### Problem z bazÄ… danych
```bash
cd server
npx prisma db push
npx prisma generate
```

#### Problem z pamiÄ™ciÄ… wektorowÄ…
```bash
# JeÅ›li pamiÄ™Ä‡ wektorowa nie dziaÅ‚a, sprawdÅº inicjalizacjÄ™
# Model embeddings pobiera siÄ™ przy pierwszym uruchomieniu (~50MB)
# SprawdÅº logi serwera w poszukiwaniu bÅ‚Ä™dÃ³w inicjalizacji

# Weryfikacja spÃ³jnoÅ›ci pamiÄ™ci
curl -X POST http://localhost:3001/api/memory/validate/USER_ID

# Statystyki pamiÄ™ci
curl http://localhost:3001/api/memory/stats/USER_ID
```

#### Problem z TypeScript
```bash
# Client
cd client
npm run build

# Server
cd server
npm run build
```

#### Problemy z portami
- ZmieÅ„ porty w `client/vite.config.ts` i `server/src/server.ts`
- Upewnij siÄ™, Å¼e porty 3001 i 5173 sÄ… wolne

#### Build aplikacji desktop nie dziaÅ‚a
```bash
# WyczyÅ›Ä‡ wszystko
npm run release:clean
rm -rf node_modules */node_modules

# Reinstall
npm install

# Test build
npm run release:test
npm run release:build:win
```

### FAQ ğŸ™‹â€â™‚ï¸

**Q: Czy aplikacja wymaga internetu?**
A: Tak, do komunikacji z API dostawcÃ³w AI (OpenAI, Google, Anthropic).

**Q: Gdzie sÄ… przechowywane dane?**
A: Lokalnie w SQLite database w folderze aplikacji.

**Q: Czy mogÄ™ uÅ¼ywaÄ‡ bez kluczy API?**
A: Nie, aplikacja wymaga wÅ‚asnych kluczy API do dziaÅ‚ania.

**Q: Czy mogÄ™ exportowaÄ‡ rozmowy?**
A: Obecnie nie ma wbudowanej funkcji, ale planowana w przyszÅ‚oÅ›ci.

**Q: Aplikacja zuÅ¼ywa duÅ¼o RAM**
A: To normalne dla aplikacji Electron. MoÅ¼na ograniczyÄ‡ w Task Manager.

**Q: Czy sÄ… auto-updates?**
A: Obecnie nie, naleÅ¼y pobieraÄ‡ nowe wersje manualnie z GitHub.

### ğŸ“ Wsparcie

**GitHub Issues**: [github.com/your-username/myllm-chat/issues](https://github.com/your-username/myllm-chat/issues)

**Przed zgÅ‚oszeniem problemu**:
1. SprawdÅº czy problem jest juÅ¼ zgÅ‚oszony
2. DoÅ‚Ä…cz informacje o systemie (OS, wersja)
3. DoÅ‚Ä…cz logi bÅ‚Ä™dÃ³w (jeÅ›li sÄ…)
4. Opisz kroki do reprodukcji problemu

## ğŸ¤ Contribution

1. Fork projektu
2. StwÃ³rz branch dla nowej funkcjonalnoÅ›ci (`git checkout -b feature/AmazingFeature`)
3. Commit zmiany (`git commit -m 'Add some AmazingFeature'`)
4. Push do brancha (`git push origin feature/AmazingFeature`)
5. OtwÃ³rz Pull Request

## ğŸ“„ Licencja

Ten projekt jest licencjonowany na licencji MIT - zobacz plik [LICENSE](LICENSE) dla szczegÃ³Å‚Ã³w.

## ğŸ’¡ Motywacja

Projekt powstaÅ‚ z frustracji zwiÄ…zanej z:

- **Wysokimi kosztami** abonamentÃ³w ChatGPT Plus/Pro
- **Ograniczeniami** w darmowych wersjach
- **Brakiem wyboru** modeli AI w jednym miejscu
- **Problemami z prywatnoÅ›ciÄ…** danych

MyLLM Chat rozwiÄ…zuje te problemy oferujÄ…c:

- âœ… **PeÅ‚nÄ… kontrolÄ™** nad kosztami (pÅ‚acisz tylko za uÅ¼ycie)
- âœ… **WybÃ³r modeli** AI w jednym interfejsie
- âœ… **PrywatnoÅ›Ä‡** (klucze API tylko u Ciebie)
- âœ… **Brak limitÃ³w** (poza limitami samych API)

## ğŸ¯ Roadmapa

### âœ… Zrealizowane
- [x] **PamiÄ™Ä‡ wektorowa** - inteligentna pamiÄ™Ä‡ miÄ™dzy rozmowami
- [x] **Analiza intencji** - rozrÃ³Å¼nianie kontynuacji od odwoÅ‚aÅ„ do przeszÅ‚oÅ›ci  
- [x] **ZarzÄ…dzanie pamiÄ™ciÄ…** - konfiguracja prywatnoÅ›ci i agresywnoÅ›ci
- [x] **Synchronizacja danych** - automatyczne czyszczenie przy usuwaniu czatÃ³w

### ğŸ”„ W planach
- [ ] **Interface pamiÄ™ci** - panel zarzÄ…dzania pamiÄ™ciÄ… w UI
- [ ] **Docker** - konteneryzacja aplikacji
- [ ] **Streaming odpowiedzi** - real-time streaming od AI
- [ ] **Export rozmÃ³w** - PDF/JSON/Markdown (z opcjÄ… exportu pamiÄ™ci)
- [ ] **Wyszukiwanie semantyczne** - wyszukiwarka w historii i pamiÄ™ci
- [ ] **Ciemny motyw** - przeÅ‚Ä…cznik day/night mode
- [ ] **Wtyczki** - system rozszerzeÅ„
- [ ] **API wÅ‚asne** - RESTful API dla integracji
- [ ] **WiÄ™cej modeli** - Cohere, Mistral, Llama
- [ ] **PamiÄ™Ä‡ wspÃ³Å‚dzielona** - opcja dzielenia pamiÄ™ci miÄ™dzy uÅ¼ytkownikami (zespoÅ‚y)

---

**â­ JeÅ›li projekt Ci siÄ™ podoba, zostaw gwiazdkÄ™ na GitHubie!**
